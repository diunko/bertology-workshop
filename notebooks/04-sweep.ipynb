{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformers.data.processors.glue import MrpcProcessor\n",
    "import torch\n",
    "from transformers import (\n",
    "    BertModel,\n",
    "    BertTokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "bert = BertModel.from_pretrained('bert-base-cased', output_attentions=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import glue_convert_examples_to_features as convert_examples_to_features\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, RandomSampler, DataLoader, random_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_mnli_bert_dataloaders():\n",
    "  # ----------------------\n",
    "  # TRAIN/VAL DATALOADERS\n",
    "  # ----------------------\n",
    "  train = processor.get_train_examples('MRPC')\n",
    "  features = convert_examples_to_features(train,\n",
    "                                          tokenizer,\n",
    "                                          label_list=['contradiction','neutral','entailment'],\n",
    "                                          max_length=128,\n",
    "                                          output_mode='classification',\n",
    "                                          pad_on_left=False,\n",
    "                                          pad_token=tokenizer.pad_token_id,\n",
    "                                          pad_token_segment_id=0)\n",
    "  train_dataset = TensorDataset(torch.tensor([f.input_ids for f in features], dtype=torch.long),\n",
    "                                torch.tensor([f.attention_mask for f in features], dtype=torch.long),\n",
    "                                torch.tensor([f.token_type_ids for f in features], dtype=torch.long),\n",
    "                                torch.tensor([f.label for f in features], dtype=torch.long))\n",
    "\n",
    "  nb_train_samples = int(0.95 * len(train_dataset))\n",
    "  nb_val_samples = len(train_dataset) - nb_train_samples\n",
    "\n",
    "  bert_mnli_train_dataset, bert_mnli_val_dataset = random_split(train_dataset, [nb_train_samples, nb_val_samples])\n",
    "\n",
    "  # train loader\n",
    "  train_sampler = RandomSampler(bert_mnli_train_dataset)\n",
    "  bert_mnli_train_dataloader = DataLoader(bert_mnli_train_dataset, sampler=train_sampler, batch_size=32)\n",
    "\n",
    "  # val loader\n",
    "  val_sampler = RandomSampler(bert_mnli_val_dataset)\n",
    "  bert_mnli_val_dataloader = DataLoader(bert_mnli_val_dataset, sampler=val_sampler, batch_size=32)\n",
    "\n",
    "\n",
    "  # ----------------------\n",
    "  # TEST DATALOADERS\n",
    "  # ----------------------\n",
    "  dev = processor.get_dev_examples('MNLI')\n",
    "  features = convert_examples_to_features(dev,\n",
    "                                          tokenizer,\n",
    "                                          label_list=['contradiction','neutral','entailment'],\n",
    "                                          max_length=128,\n",
    "                                          output_mode='classification',\n",
    "                                          pad_on_left=False,\n",
    "                                          pad_token=tokenizer.pad_token_id,\n",
    "                                          pad_token_segment_id=0)\n",
    "\n",
    "  bert_mnli_test_dataset = TensorDataset(torch.tensor([f.input_ids for f in features], dtype=torch.long),\n",
    "                                torch.tensor([f.attention_mask for f in features], dtype=torch.long),\n",
    "                                torch.tensor([f.token_type_ids for f in features], dtype=torch.long),\n",
    "                                torch.tensor([f.label for f in features], dtype=torch.long))\n",
    "\n",
    "  # test dataset\n",
    "  test_sampler = RandomSampler(bert_mnli_test_dataset)\n",
    "  bert_mnli_test_dataloader = DataLoader(bert_mnli_test_dataset, sampler=test_sampler, batch_size=32)\n",
    "\n",
    "  return bert_mnli_train_dataloader, bert_mnli_val_dataloader, bert_mnli_test_dataloader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}